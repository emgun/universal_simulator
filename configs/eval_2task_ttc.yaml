# Evaluation config for 2-task baseline WITH Test-Time Conditioning
# Based on train_pdebench_2task_baseline.yaml + TTC settings from burgers_upt

seed: 42
deterministic: false
benchmark: true

data:
  task: [advection1d, darcy2d]
  split: train  # Use train split (already downloaded on instance)
  root: data/pdebench
  patch_size: 1

latent:
  dim: 128
  tokens: 128

operator:
  architecture_type: pdet_stack
  pdet:
    input_dim: 128
    hidden_dim: 384
    depth: 12
    num_heads: 8
    attention_type: standard
    qk_norm: true
    mlp_ratio: 4.0
    drop_path: 0.1
    dropout: 0.0

diffusion:
  latent_dim: 128
  hidden_dim: 384

training:
  batch_size: 8
  time_stride: 2
  dt: 0.1
  num_workers: 0
  use_parallel_encoding: true
  pin_memory: true
  prefetch_factor: 4
  amp: true
  compile: false

# Test-Time Conditioning Settings (Memory-Optimized for 40GB GPU)
ttc:
  enabled: true
  steps: 1               # Single-step for evaluation speed
  candidates: 4          # Reduced to 4 for memory (40GB GPU limit)
  beam_width: 2          # Reduced to 2 for memory
  horizon: 1
  residual_threshold: 0.35
  gamma: 1.0
  max_evaluations: 100   # Reduced for memory

  sampler:
    tau_range: [0.15, 0.85]
    noise_std: 0.05
    noise_schedule: [0.08, 0.05, 0.02]

  reward:
    analytical_weight: 1.0
    grid: [32, 32]         # Reduced from [64,64] for memory (4x less)

    # PDEBench field names (task-specific)
    # Advection1D: 'u' field (velocity)
    # Darcy2D: 'p' field (pressure)
    mass_field: null       # Will use first available field for mass conservation
    energy_field: null     # Not applicable (neither task conserves energy)
    momentum_field: []

    # Physics-appropriate weights for conservative PDEs
    # Both advection & darcy CONSERVE mass but allow negative values
    weights:
      mass: 1.0                     # PRIMARY reward: mass/quantity conservation
      energy: 0.0                   # Not applicable (vs Burgers which uses 0.1)
      penalty_negative: 0.0         # No penalty (vs Burgers which uses 0.5)

    critic:
      weight: 0.0         # Use analytical rewards only
      hidden_dim: 256
      dropout: 0.1

  decoder:
    latent_dim: 128       # Match training latent dim
    query_dim: 2          # 2D max (advection is 1D, darcy is 2D)
    hidden_dim: 288       # 2.25× latent_dim
    mlp_hidden_dim: 384   # 3× latent_dim
    num_layers: 3
    num_heads: 8
    frequencies: [1.0, 2.0, 4.0, 8.0]
    output_channels:
      u: 1                # Generic field name for PDEBench single-channel tasks

evaluation:
  enabled: true

logging:
  wandb:
    enabled: true
    project: universal-simulator
    entity: emgun-morpheus-space
    tags: [pdebench, multi-task, 2task-ttc, eval-only, 128d]
