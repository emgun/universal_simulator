# 2-Task 192d: advection1d + darcy2d with increased latent capacity
# Purpose: Scale from 128d (NRMSE 0.1925) to 192d for < 0.15 target
# Capacity: 2.25× increase vs 128d baseline

seed: 42
deterministic: false
benchmark: true

data:
  task: [advection1d, darcy2d]  # Multi-task list
  split: train
  root: data/pdebench
  patch_size: 1

  # Task sampling strategy
  task_sampling:
    strategy: "balanced"  # Equal samples per task per epoch

latent:
  dim: 192          # Scaled from 128 (1.5× increase)
  tokens: 192       # Scaled from 128 (1.5× increase)

operator:
  architecture_type: pdet_stack    # Pure transformer (from Phase 4)
  pdet:
    input_dim: 192                 # Match latent.dim
    hidden_dim: 576                # 3× latent_dim (192 × 3 = 576)
    depth: 12                      # Keep same depth
    num_heads: 8
    attention_type: standard
    qk_norm: true
    mlp_ratio: 4.0
    drop_path: 0.1
    dropout: 0.0

diffusion:
  latent_dim: 192   # Match latent.dim
  hidden_dim: 576   # Match operator

training:
  batch_size: 6     # Reduce from 8 (larger latent size)
  accum_steps: 8    # Effective batch = 48
  time_stride: 2
  dt: 0.1
  patience: 10

  num_workers: 0  # Avoid deadlock with PreloadedCache
  use_parallel_encoding: true
  pin_memory: true
  prefetch_factor: 4

  amp: true
  compile: false
  grad_clip: null
  ema_decay: 0.999

  # UPT Inverse Losses (from Phase 4)
  lambda_inv_enc: 0.01
  lambda_inv_dec: 0.01
  use_inverse_losses: true
  inverse_loss_frequency: 1
  inverse_loss_warmup_epochs: 5
  inverse_loss_max_weight: 0.05

  # Query-Based Training (Phase 4.1)
  query_sampling:
    enabled: true
    num_queries: 2048
    strategy: uniform

  # Physics Priors + Latent Regularization (Phase 4.2 + 4.3)
  physics_priors:
    enabled: true
    lambda_divergence: 0.0
    lambda_conservation: 0.0
    lambda_boundary: 0.05
    lambda_positivity: 0.0
    lambda_latent_norm: 1.0e-4
    lambda_latent_diversity: 1.0e-4

  lambda_spectral: 0.05

  # Per-task metric logging
  log_per_task_metrics: true

stages:
  operator:
    epochs: 40      # Match golden config

    optimizer:
      name: muon_hybrid
      lr: 1.4e-3
      weight_decay: 0.03
      muon_momentum: 0.95
      muon_ns_steps: 5
      muon_backend: auto
      betas: [0.9, 0.999]

  diff_residual:
    epochs: 15
    patience: 5
    optimizer:
      name: muon_hybrid
      lr: 3.0e-4
      weight_decay: 0.01

  consistency_distill:
    epochs: 10
    patience: 5
    optimizer:
      name: muon_hybrid
      lr: 3.0e-4
      weight_decay: 0.01

logging:
  wandb:
    enabled: true
    project: universal-simulator
    entity: emgun-morpheus-space
    tags: [pdebench, multi-task, 2task-192d, capacity-scaling]

evaluation:
  enabled: true
