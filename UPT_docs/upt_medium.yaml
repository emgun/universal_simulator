# ===== UPT Medium (≈17–30M params) =====
# Goal: balanced fidelity vs. speed; default for full experiments
experiment_name: upt_medium

seed: 1337

dataset:
  name: transient_flow
  root: /PATH/TO/DATASET_ROOT
  stats_path: /PATH/TO/DATASET_ROOT/stats.json
  max_input_points: 64000
  query_points_per_batch: 6144
  segment:
    steps: 3
    dt: 1
  splits:
    train: train.txt
    val: val.txt
    test: test.txt

model:
  encoder:
    cls: CfdGnnPoolTransformerPerceiver
    num_supernodes: 1024
    gnn_dim: 192
    gnn_depth: 4
    enc_dim: 256
    enc_depth: 6
    enc_num_attn_heads: 6
    perc_dim: 256
    perc_num_attn_heads: 6
    num_latent_tokens: 512

  approximator:
    cls: LatentTransformer
    latent_dim: 256
    depth: 8
    num_attn_heads: 6
    drop_path_rate: 0.1

  decoder:
    cls: CfdTransformerPerceiver
    dim: 256
    depth: 6
    num_attn_heads: 6
    perc_dim: 256
    perc_num_attn_heads: 6
    use_last_norm: true
    clamp: null

  channels:
    in: 3
    out: 3

losses:
  pred: mse
  inv_encode_weight: 0.3
  inv_decode_weight: 0.3
  reg_weight: 0.0

trainer:
  epochs: 100
  batch_size: 2
  grad_accum_steps: 2
  amp: bf16
  grad_clip_norm: 1.0
  ema:
    enabled: true
    decay: 0.999

optimizer:
  name: adamw
  lr: 2.0e-4
  weight_decay: 1.0e-2
  betas: [0.9, 0.999]

schedule:
  name: cosine
  warmup_steps: 2000
  min_lr: 5.0e-6

eval:
  rollout:
    enabled: true
    steps: 200
    decode_dense: false

logging:
  wandb:
    enabled: true
    project: UPT
    mode: online
  checkpoint:
    save_best_metric: val/mse
    save_every_epochs: 5
    outdir: ./checkpoints/upt_medium
