include: train_burgers_quality_v2.yaml

# 32-dim v2: Comprehensive improvements to push baseline below 0.5 NRMSE
# 
# Strategy: Architecture + Training + Curriculum Learning
# 
# Current: Baseline 0.78, TTC 0.09
# Target:  Baseline 0.40, TTC 0.04-0.05
# 
# Improvements:
# 1. ARCHITECTURE: Larger hidden_dim (64→96), more depth, better attention
# 2. TRAINING: More epochs (15→25), better regularization, grad clipping
# 3. CURRICULUM: Progressive difficulty, longer warmup, data augmentation

data:
  task: burgers1d
  split: train
  root: data/pdebench
  patch_size: 1
  download:
    test_val_datasets: burgers1d_full_v1
    train_files:
      - source: full/burgers1d/burgers1d_train_000.h5
        symlink: burgers1d_train.h5

latent:
  dim: 32
  tokens: 32

training:
  time_stride: 2  # Start easier, will add curriculum
  batch_size: 12
  
  # pru2jxc4 parallel settings
  num_workers: 8
  use_parallel_encoding: true
  
  latent_cache_dir: data/latent_cache
  checkpoint_interval: 50
  
  distill_micro_batch: 3
  distill_num_taus: 5
  
  compile: true
  pin_memory: true
  
  # Data augmentation for better generalization
  augmentation:
    noise_std: 0.01      # Add small noise to inputs
    time_jitter: 0.05    # Random time perturbations
    
  tau_distribution:
    type: beta
    alpha: 1.2
    beta: 1.2

operator:
  pdet:
    input_dim: 32
    hidden_dim: 96        # ↑ 1.5x larger (was 64)
    depths: [2, 2, 2]     # ↑ Deeper (was [1, 1, 1])
    group_size: 12        # Divides 96 evenly
    num_heads: 6          # More attention heads
    
    # Architecture improvements
    use_residual: true    # Add skip connections
    dropout: 0.05         # Light regularization
    layer_norm: true      # Better training stability

diffusion:
  latent_dim: 32
  hidden_dim: 96          # ↑ Match operator (was 64)
  num_layers: 4           # ↑ Deeper (was 3)
  dropout: 0.05

stages:
  operator:
    epochs: 25            # ↑ More epochs (was 15)
    
    # Curriculum learning: progressive difficulty
    curriculum:
      enabled: true
      warmup_epochs: 5    # Easy examples first
      time_stride_schedule:
        - [0, 4]          # Epochs 0-4: stride=4 (easiest)
        - [5, 10]         # Epochs 5-10: stride=3
        - [11, 25]        # Epochs 11-25: stride=2 (hardest)
    
    optimizer:
      name: adamw
      lr: 1.0e-3          # Constant LR (pru2jxc4 style)
      weight_decay: 0.03  # ↑ Slightly higher (was 0.02)
      betas: [0.9, 0.999]
    
    # Gradient management
    grad_clip: 1.0        # Prevent exploding gradients
    grad_accumulation: 4  # Effective batch = 48
    
    # Learning rate warmup
    warmup:
      enabled: true
      epochs: 3
      start_lr: 1.0e-4

  diff_residual:
    epochs: 8             # ↑ More epochs (was 5)
    grad_clip: 1.0
    ema_decay: 0.999
    
    optimizer:
      name: adamw
      lr: 5.0e-5          # ↑ Slightly higher (was 3e-5)
      weight_decay: 0.015 # ↑ More regularization
      betas: [0.9, 0.999]
    
    scheduler:
      name: cosineannealinglr
      t_max: 8
      eta_min: 3.0e-6

  consistency_distill:
    epochs: 8             # ↑ More epochs (was 6)
    batch_size: 6
    
    optimizer:
      name: adamw
      lr: 3.0e-5          # ↑ Slightly higher (was 2e-5)
      weight_decay: 0.015
      betas: [0.9, 0.999]
    
    scheduler:
      name: cosineannealinglr
      t_max: 8
      eta_min: 2.0e-6

evaluation:
  enabled: true

ttc:
  enabled: true
  steps: 1
  candidates: 8           # ↑ More candidates (was 6)
  beam_width: 3           # ↑ Wider beam (was 2)
  horizon: 2
  residual_threshold: 0.35
  gamma: 1.0
  max_evaluations: 150    # ↑ More evaluations (was 100)
  
  sampler:
    tau_range: [0.15, 0.85] # ↑ Wider range (was 0.2-0.8)
    noise_std: 0.015        # ↑ More exploration
    noise_schedule: [0.03, 0.015, 0.005] # Progressive refinement
    
  reward:
    analytical_weight: 1.0
    grid: [64, 64]
    mass_field: rho
    energy_field: e
    momentum_field: []
    weights:
      mass: 1.2           # ↑ Higher weight (was 1.0)
      energy: 0.15        # ↑ Higher weight (was 0.1)
      penalty_negative: 0.6 # ↑ Stricter (was 0.5)
    critic:
      weight: 0.0
      hidden_dim: 256
      dropout: 0.1
      
  decoder:
    latent_dim: 32
    query_dim: 2
    hidden_dim: 96        # ↑ Match operator (was 64)
    mlp_hidden_dim: 128   # ↑ Larger MLP (was 64)
    num_layers: 3         # ↑ Deeper (was 2)
    num_heads: 6          # ↑ More heads (was 4)
    frequencies: [1.0, 2.0, 4.0, 8.0] # ↑ More frequencies
    output_channels:
      rho: 1
      e: 1

logging:
  wandb:
    enabled: true
    project: universal-simulator
    entity: emgun-morpheus-space
    run_name: burgers32-v2-comprehensive
    tags: [32dim, v2_improved, architecture_upgrade, curriculum_learning, unified_pipeline]

# EXPECTED OUTCOMES:
# ─────────────────────────────────────────────────────────────────────────────
#
# Baseline (no TTC):
#   Current: 0.7845 NRMSE (very poor)
#   Target:  0.35-0.45 NRMSE (2x improvement)
#   
#   Improvements from:
#   - Larger model capacity (96 vs 64 hidden)
#   - Deeper architecture (2x depth)
#   - Curriculum learning (easier→harder)
#   - More training (25 vs 15 epochs)
#   - Better regularization
#
# With TTC:
#   Current: 0.0921 NRMSE (excellent)
#   Target:  0.04-0.05 NRMSE (2x improvement)
#   
#   Improvements from:
#   - Better baseline model
#   - Improved TTC (more candidates, wider beam)
#   - Better decoder architecture
#   - More exploration in sampling
#
# IF SUCCESSFUL:
#   → 32-dim becomes SOTA at its size class
#   → Proves curriculum learning + architecture scaling work
#   → TTC improvement compounds with baseline improvement
#   → Publication-worthy: "Curriculum Learning + TTC for PDE Solving"
#
# ─────────────────────────────────────────────────────────────────────────────
# Training time: ~35 min on H200 (longer due to more epochs + deeper model)
# Cost: ~$1.25 @ $2.11/hr
#
# Model size: ~350KB (was ~250KB due to larger architecture)
#
# Key innovation: Curriculum learning with time_stride schedule
#   - Start easy (stride=4, every 4th timestep)
#   - Progress to medium (stride=3)
#   - End hard (stride=2, standard difficulty)
#   This allows model to learn coarse dynamics first, then refine

